---
title: Neo4j数据数据入库方案（OLD）
tags: 图库
---

## 第一章 Neo4j数据入库方式
Neo4j支持多种方式的数据入库的方式包含Neo4j Import、[Batch Import]("" "Batch Import")、Load CSV、Cypher。

下面按照数据量级别进行划分：

- 千万级别以上数据量：BatchImport和Neo4jImport。只能在初始化建库使用，已经存储的库不支持。

- 十万到千万级别的数据量：Load CSV的方式，支持已有库的数据追加，适合大增量级别和中等数据量全量入库。

- 小数据量级别五万级以下：Cypher的方式，支持已有库的小数据量增量入库，灵活方便，支持事务。

## 第二章 图库信息

**业务图库**：是根据现有的业务基础和特定需求进行建库，其中节点和关系可以进行系统的评估和预测，选择可行性的入库方式。

**业务需求**：基于公安内部基础资源库进行人员信息的轨迹和行为进行关联的一种关系图。可以基于Cypher查询分析人员的行为轨迹进行人与人之间的各种关系查询。

### 2.1.人的基本信息

姓名、证件号码、家庭住址、户的家庭成员、详细地址、婚姻状态等

### 2.2.人的轨迹行为

旅馆住宿、乘坐航班、乘坐火车、乘坐客车、上网、出入境、迁移、租赁房屋等。

### 2.3.建库的目的

- 基于人的轨迹行为的查询，可视化展示。

- 基于人的轨迹行为通过特定的规则进行人与人之间存在的行为轨迹关系进行数据挖掘和分析，得出存在的关系脉络和可能存在的关系网。

### 2.4.图库数据量预估

前提先得了解[数据建模]("" "数据建模")才能进行相关的信息的评估，可视化分析的根据贵州的情况最初预估在5亿-10亿的节点之间、10亿-30亿的边，因为各个省的信息有差异所以此只是一个基本的评估。

## 第三章 全量方案

基于上面图库数据量预估，以及参考[数据建模]("" "数据建模")手册可以得出，图库的全量入库只能是Neo4j Import 或者 Batch Import进行导入新键库。

查看此章节前必看[数据建模手册]("" "数据建模手册")和[Batch Import手册]("" "Batch Import手册")，也可参考[Neo4j 操作手册]("" "Neo4j 操作手册")。

### 3.1.全量方式选择

本方案通过HBase资源库生成CSV文件，然后选择Batch Import读取进行全量数据的导入。

**选择Batch Import具体原因有以下几点：**

1. Batch Import是大批量处理的Neo4j的一直快速有效的方式。

2. Batch Import可以支持索引的创建而Neo4j Import导入时候不支持索引创建。

3. Batch Import 不依赖Neo4j的安装，在任何服务器都可以执行，生成库后可以直接复制到需要使用的Neo4j的安装服务器上即可，而Neo4j Import必须依赖Neo4j的安装服务器才能使用。

4. Batch Import支持可配置内存，而Neo4j Import只能依赖Neo4j安装的使用内存。

**通用缺点：**

1. 不管是Neo4j Import 还是Batch Import都不支持已经存在的图库进行数据追加，只能在第一次初始化使用通过Import命令进行新图库创建。

2. 需要先提前准备好需要入库的CSV数据文件

3. 如果已经生成完成了图库，如果需要在添加某个类别的一个大数据量级别的节点和关系，需要全部重新建库，这是致命的缺陷属于Neo4j设计上的缺陷。

4. 导入CSV如果关系中依赖的节点ID在节点CSV文件中找不到将可能会异常。

### 3.2.全量方案图

通过下面图进行全量方案简要流程说明：

![](https://v4liulv.github.io/assets/image/1522374353832_25.png)

- 通过ODBA标准库或HBase资源库、其他可能来源库，生成图库规则的CSV数据文件

- CSV数据文件包含节点和关系的数据文件，再通过Batch Import将CSV数据文件生成图数据库



### 3.3.CSV数据文件

#### 3.3.1.使用方式

通过MapReduce读取源库的方式生成CSV数据文件
- 方式一：MR读取Oracle标准库生成CSV（支持）

- 方式二：MR读取HBase资源库生成CSV（推荐）

本案例使用方式二。

#### 3.3.2.实现原理

- 通过Oracle或者HBase某类资源作为MapReduce的输入
- 然后在通过Map读取字段配置信息，过滤处理
- 再通过Reduce读取配置信息提供的规则组装生成输出文件（CSV文件）输出到HDFS
- 从HDFS拷贝到本地

问题：所有的关系都是基于人员信息去关联的，那么人员信息在现在标准库是找不到这样一个一个已经有资源表，只能通过多个轨迹类资源表去合成大宽表，这样就需要合成实现抽取一个大宽表到User的合成表中，下面将介绍这部分内容，合成身份证号的大宽表。

### 3.4.身份证号大宽表

通过读取配置信息作为输入过滤，读取MR的配置信息进行MR抽取到User人员信息的大宽表。

**配置信息表：**
- 大宽表MR抽取的公共配置信息 B_BIGWID_TAB_GGPZXX
- 大宽表MR的JOB配置表 B_BIGWID_TAB_TASK
- 大宽表的列配置表 B_BIGWID_TAB_QUALIFIER
- 大宽表User身份证号配置信息 B_USER_BIGTAB_PZXXB

#### 3.5.数据库配置表的表公共字段结构

**备注**：*这是后续所有配置表的公共字段，每个表都包含这些字段，后续不再出现*

|  字段 |  字段长度 |  是否允许为空 |  默认值 | 描述  |
| ------------ | ------------ | ------------ | ------------ | ------------ |
|  SYSTEMID | VARCHAR2(50)  |  N | SYS_GUID()  |  主键 |
|  CREATE_USER | VARCHAR2(50)  |  N  | 'SYS' |  创建人 |
|  CREATE_TIME |  DATE |  N |  SYSDATE | 创建时间  |
|  UPDATE_TIME | DATE  | Y  |  SYSDATE | 更新时间  |
| SCBZ  | VARCHAR2(4)  |  N |  0 |  删除标志，0代表未删除，1代表已删除 |
| BLZD1  |  VARCHAR2(30) | Y  |   | 保留字段1  |
| BLZD2  |  VARCHAR2(100) | Y  |   | 保留字段2  |
| BLZD3  |  VARCHAR3(300) | Y  |   | 保留字段3  |
| BLZD4  |  VARCHAR4(500) | Y  |   | 保留字段4  |
| BLZD5  |  VARCHAR4(1000) | Y  |   | 保留字段5  |

### 3.6 全量数据入库配置表信息

#### 3.6.1 B_BIGWID_TAB_GGPZXX
大宽表MR抽取的公共配置信息表

|  字段 |  字段长度 |  是否允许为空 |  默认值 | 描述  |
| ------------ | ------------ | ------------ | ------------ | ------------ |
|  BIGWID_TYPE | VARCHAR2(100)  |  N |   |  大宽表类型，如01代表User大宽表，02代表关系分析宽表，人员标签大宽表代表03，标识号大宽04 |
| BIGWID_DEL | VARCHAR2(1000) | Y |  | 大宽表类型详情 |
| TARGET_TABLE_ROWKEY_DELIM  | VARCHAR2(10)  |  Y |   |  ROWKEY分割符 |
| TARGET_TABLE_VALUE_DELIM  |  VARCHAR2(10) | Y  |  |  值的分隔符号 |
| SCAN_CACHE  | NUMBER(4)  |  N | 1000  | 一次RPC请求数，默认为1000  |
| SCAN_BATCH  | NUMBER(4)  |  N |  100 | 一次请求的最大的列数，默认为100  |
| IS_COMPRESS  |  NUMBER(2) | N  |  0 | 是否启动压缩，0代表否，1代表是  |
| COMPRESS_TYPE  | VARCHAR2(50)  | Y  |   | 01为default,02为ZIP2, 03为snapp  |

#### 3.6.2 B_BIGWID_TAB_TASK
大宽表MR的JOB配置表

|  字段 |  字段长度 |  是否允许为空 |  默认值 | 描述  |
| ------------ | ------------ | ------------ | ------------ | ------------ |
| BIGWID_ID  | VARCHAR2(32)  | N  |   | 大宽表类型外键一对多对应GGPZXX表的主键  |
| TASK_NAME  | VARCHAR2(200)  |  N |   | 区分各个抽取来源表的Shell的参数，唯一  |
| JOB_NAME  | VARCHAR2(200)  | N  |   | 运行MR-JOB作业的名称  |
| JAR_NAME  | VARCHAR2(100)  |  Y |   | MR-JAR包名  |
| TMP_TARGET_DIR  | VARCHAR2(300)  | N  |   | 输出HDFS的临时目录  |
| SOURCE_TABLE  | VARCHAR2(100)  | N  |   | HBASE的源表英文名（大写）  |
| SOURCE_TABLE_FAMILY  | VARCHAR2(100)  | N  | CF  | MR输入源表的列族  |
| TARGET_TABLE  | VARCHAR2(100)  | N  |   | MR输出到HBASE表名  |
| TARGET_TABLE_FAMILY  | VARCHAR2(20)  | N  | CF  | MR输出表目标表的列族，默认CF  |
| TARGET_TABLE_ROWKEY  | VARCHAR2(100)  | N  | ZJHM  | 输出表的主键，也就是输出表主键来源输出表那个字段或者那些字段  |
| TARGET_TABLE_QUALIFIER  | VARCHAR2(200)  | Y  |   | 输出表的列名，可以配置多个列名，来源输入的表列名称  |
| TARGET_VALUE  | VARCHAR2(200)  | Y  |   | 输出表列值，来源输入表的多个字段，如zd1:zd2..  |

#### 3.6.3 B_BIGWID_TAB_QUALIFIER

大宽表的列配置表

|  字段 |  字段长度 |  是否允许为空 |  默认值 | 描述  |
| ------------ | ------------ | ------------ | ------------ | ------------ |
| TASK_NAME  | VARCHAR2(100)  | N  |   | task name 启动作业名，task外键与B_BIGWID_TAB_TASK的taskName一对一关联  |
| QUALIFIER_NAME  | VARCHAR2(100)  | N  |   | 列名  |
| QUALIFIER_VALUE  | VARCHAR2(100)  | N  |   | 列值对应源表列名  |
| QUALIFIER_NAME_IS_TIME  | NUMBER(2)  | N  | 0  | 是否是日期字段  |
| QUALIFIER_NAME_DATA_TYPE  | NUMBER(2)  | N  | 0  | 数据格式类型，0代表201501格式，1代表DATE类型2015/01,2代表毫秒格式  |
| QUALIFIER_NAME_TYPE  | NUMBER(2)  | N  | 0  | 0代表是源字段的值，1代表是配置就直接赋值  |
| QUALIFIER_NAME_IS_DATEZH  | NUMBER(2)  | N  | 0  | 列值是否是日期字段  |
| QUALIFIER_VALUE_DATA_TYPE  | NUMBER(2)  | N  | 0  | 列值格式类型，0代表201501格式，1代表DATE类型2015/01,2代表毫秒格式  |
| QUALIFIER_VALUE_TYPE  | NUMBER(2)  | N  | 0  | 列值，0代表是源字段的值，1代表是配置就直接赋值  |
| QUALIFIER_VALUE_IS_DATEZH  | NUMBER(2)  | N  | 0  | 列值，是否进行日期字段转换标准格式201701..,0代表否，1代表是  |

#### 4.6.4 B_USER_BIGTAB_PZXXB
大宽表User身份证号配置信息

|  字段 |  字段长度 |  是否允许为空 |  默认值 | 描述  |
| ------------ | ------------ | ------------ | ------------ | ------------ |
| CODE  | VARCHAR2(10)  | N  |   | code值,区分某类别大表的标识符  |
| SOURCE_TABLE_YWMC  | VARCHAR2(30)  | N  |   | 源表英文名  |
| SOURCE_TABLE_ZWMC  | VARCHAR2(100)  | N  |   | 源表中文名  |
| ZJHM_ZD_YWMC  | VARCHAR2(30)  | N  |   | 证件号码字段英文名  |
| ZJHM_ZD_ZWMC  | VARCHAR2(100)  | N  |   | 证件号码字段中文名  |
| XM_ZD_YWMC  | VARCHAR2(30)  | N |   | 姓名字段英文名  |
| XM_ZD_ZWMC  | VARCHAR2(100)  | Y  |   | 姓名字段中文名  |
| HBASE_TABLE_NAME  | VARCHAR2(30)  | N  |   | HBASE入库表名，大写  |

#### 3.6.5 现场需要配置修改
需要根据现场实际HBase资源库资源库表进行适配修改：

- **B_BIGWID_TAB_TASK表**
1. 修改B_BIGWID_TAB_TASK中的关联资源表名的SOURCE_TABLE
2. 修改B_BIGWID_TAB_TASK中的TARGET_TABLE_ROWKEY为关联资源表名的身份证号码字段名称

-  **B_BIGWID_TAB_QUALIFIER表**
1. 修改B_BIGWID_TAB_QUALIFIER表中的TaskName和QUALIFIER_NAME适配修改QUALIFIER_VALUE的值其对应字段名称。

- **B_USER_BIGTAB_PZXXB表**
1. 修改其SOURCE_TABLE_YWMC（源表英文名）、SOURCE_TABLE_ZWMC（源表中文名）
2. ZJHM_ZD_YWMC（证件号码字段英文名）、ZJHM_ZD_ZWMC（证件号码字段中文名）
3. 如果表中有姓名，配置XM_ZD_YWMC（姓名字段英文名）、XM_ZD_ZWMC（姓名号码字段中文名）

#### 3.6.6 数据抽取生成User(身份证号)大宽表

抽取HBase资源库的数据到User(身份证号)大宽表，需要Hadoop集群有相关的执行环境。

具体步骤：
1、拷贝程序Jar包到Hadoop集群的`/home/hadoop/Kshfx/jar`目录下。
2、拷贝程序运行需要的Jar包到Hadoop集群`/home/hadoop/Kshfx/libs/`目录下。
3、拷贝运行的Shell脚本到Hadoop集群的`/home/hadoop/Kshfx/shell/`目录下。
4、给shell脚步授权执行权限
```
chmod 755 /home/hadoop/Kshfx/shell/*.sh
```
5、执行命令进行全量抽取。如下面命令抽取Hotel旅馆住宿信息表的身份证号信息到User大宽表，其他类似。
```
sh /home/hadoop/Kshfx/bin/kshxf-bigtab.sh USER_BIGWID_HOTEL
```
6、Yarn界面查看执行情况，如果成功在看下一步，异常情况在格外进行排查处理。
7、HBase shell命令查看B_USER_BIG_TABLE是否已经抽取成功。

详细信息请查看[现场实施手册]

### 3.7 生成CSV数据文件
上节已经进行User身份证号的大宽表抽取，那么需要的全部源表资源已经全部就绪，可以进行生成CSV数据文件操作。

#### 3.7.1 配置表

配置表包含：
- B_BIMP_PZXXB（BatchImportCsv的Node的创建CSV的配置表）
- B_BIMP_TITLE （BatchImport CSV的文件头配置信息表）
- B_BIMP_MR_HBASE （BatchImport CSV的MapReduce读取HBase输入的配置信息表）

##### 3.7.1.1 B_BIMP_PZXXB配置库信息表详情
B_BIMP_PZXXB（BatchImportCsv的Node的创建CSV的配置表）-提供对应Neo4j标签和类型以及源表等配置信息

|  字段 |  字段长度 |  是否允许为空 |  默认值 | 描述  |
| ------------ | ------------ | ------------ | ------------ | ------------ |
| TYPE  | VARCHAR2(10)  | N  |   | 抽取资源类型，如001为旅馆住宿，002为航班信息。。。  |
| TYPE_DET  | VARCHAR2(300)  | Y  |   | TYPE详情描述  |
| LABEL  | VARCHAR2(50)  | N  |   | 图数据库的NODE的标签  |
| SOURCE_TABLE  | VARCHAR2(50)  | N  |   | 来源表源表英文名称  |

##### 3.7.1.2 B_BIMP_TITLE （BatchImport CSV的文件头配置信息表）

B_BIMP_TITLE （BatchImport CSV的文件头配置信息表）提供对应Import CSV对应的文件头的信息，以及关联字段等配置信息。

|  字段 |  字段长度 |  是否允许为空 |  默认值 | 描述  |
| ------------ | ------------ | ------------ | ------------ | ------------ |
| TYPE_ID  | VARCHAR2(50)  | N  |   | TYPE配置信息表外键,关联B_BIMP_PZXXB表的主键  |
| T_TYPE  | VARCHAR2(10)  | N  |   | 图库的标题的类型，KIND=NEO4J_IMPORT_CSV_TITLE_TYPE, 00代表UserNode的相关配置，01代表本NODE,02代表全量的RELS  |
| TITLE_VALUE  | VARCHAR2(200)  | Y  |   | 标题的值  |
| SORT_NUM  | NUMBER(2)  | N  |   | CSV标题排序 0 1 2  |
| GLZD_TYPE  | NUMBER(2)  | N  | 0  | 关联字段类型，0代表字段，1代表直接赋值  |
| GLZD_NAME  | VARCHAR2(100)  | N  |   | 关联字段名称  |
| GLZD_ISDATE  | VARCHAR2(30)  | N  |   | 关联字段源字段是否是Date类型，0代表是毫秒，1代表date类型，2代表其他类型  |
| GLZD_ISTIME  | VARCHAR2(30)  | N  | 0  | 关联字段是否是日期字段，0代表否，1代表是日期字段  |
| GLZD_BZ  | VARCHAR2(100)  | N  |   | 关联字段标准，初始化定义后不可更改，用于Neo4j和SparkStreaming建模等  |

##### 3.7.1.3 B_BIMP_MR_HBASE （BatchImport CSV的MapReduce读取HBase输入的配置信息表）

B_BIMP_MR_HBASE （BatchImport CSV的MapReduce读取HBase输入的配置信息表）提供输入源为HBase的时候的MR读取HBase作为输入的相关配置信息。

|  字段 |  字段长度 |  是否允许为空 |  默认值 | 描述  |
| ------------ | ------------ | ------------ | ------------ | ------------ |
| TYPE_ID  | VARCHAR2(50)  | N  |   | TYPE配置信息表外键,关联B_BIMP_PZXXB表的主键  |
| JAR_NAME  | VARCHAR2(100)  | N  | gxksh.Jar  | MR运行的Jar包名称  |
| TASK_NAME  | VARCHAR2(100)  | N  |   | MR运行的作业的名称  |
| SOURCE_TABLE  | VARCHAR2(50)  | N  |   | MR输入源表英文名  |
| SCAN_CACHE  | NUMBER(4)  | N  | 1000  | HBASE的SCAN每次rpc的请求记录数,默认为1000  |
| SCAN_BATCH  | NUMBER(4)  | N  | 100  | HBASE的SCAN的每次取的列数，默认100列  |
| OUTPUT_DIR  | VARCHAR2(200)  | N  |   | MR的输出的HDFS路径  |
| NUM_REDUCE_TASKS  | NUMBER(4)  | N  | 1  | MR执行的Reduce的并发数  |
| IS_MR_OUTPUT_COMPRESS  | NUMBER(2)  | N  | 0  | 是否启用Reduce输出压缩，KIND=IS_MR_OUTPUT_COMPRESS,0代码不启动压缩，1代表启动  |
| MR_OUTPUT_COMPRESS_TYPE  | VARCHAR2(100)  | Y  |   | 压缩类型，kind=MR_OUTPUT_COMPRESS_TYPE, BZIP2,DEFAULT,SNAPP  |
| SCAN_CACHEBLOCKS  | NUMBER(2)  | N  | 0  | scan的所有数据是否放在缓存中，默认为0不放在缓存中，1代表放在缓存中  |
| MAP_SPECULATIVE_EXECUTION  | NUMBER(2)  | N  | 0  | 是否开启mr的map备用任务机制，默认0 不开启，1代表开启  |

3.7.2 现场适配配置修改

因为暂时没有Web端的应用配置支持，所以需要在配置库层面进行处理，比如初始化第一次创建图库全量前，需要修改那么配置项。

配置库实施配置时候已经生成了相关配置表和数据，因此只是需要修改其中的关联资源和关联字段即可，需要找出复合现场情况HBase资源库关联源和关联字段名。先看下面表格：
表格-类型对应的
| IMP_TYPE  | IMP_TYPE_DETAL  |
| ------------ | ------------ |
| 0200  | 人员信息  |
| 0201  | 旅馆信息  |
| 0202  | 火车信息  |
| 0203  | 名航信息  |
| 0204  | 网吧信息  |

下面的修改都需要按照此表格对应的IMP_TYPE去进行每个标签类别的修改。
**修改源表名**
```sql
select t.*, t.rowid from B_BIMP_PZXXB t;
```
根据现场的HBase基础资源库对应表名称修改其源表名SOURCE_TABLE(也就是HBase中对应资源表名称)
注意：其中的User是合成的大表，不需要修改。

**修改CSV文件头配置**
```sql
select  t.TYPE_ID, t.T_TYPE, t.TITLE_VALUE, t.SORT_NUM, t.GLZD_TYPE, t.GLZD_NAME, t.GLZD_ISDATE, t.GLZD_ISTIME, t.rowid 
from B_BIMP_TITLE T
where t.type_id = (select d.systemid from B_BIMP_PZXXB d where d.type = '0201' and d.scbz = 0)
and t.t_type = '01'
and t.SCBZ = 0
and t.GLZD_TYPE = 0
order by t.sort_num;
```
注意：
- ？其中where条件中的t.type = '0200' 是上面表格类型对应表的IMP_TYPE,0200代表人员信息标签，以此类推0201代表旅馆信息...
- ？其中where条件中的t.t_type = '01' 代表的节点还是关系，01代表节点，02代表关系，在人员信息里面没有定义关系，在相关的轨迹信息标签定义关系,也就是除了人员信息以外都要修改其关系，将t.type修改为02
- ？需要修改的字段为t.GLZD_NAME,根据现场情况的HBase库的字段进行适配修改
- ？注意字段类型是否date类型，如果在源库中或者视图库中抽取到HBase定义为Date类型，那么需要修改对应的GLZD_ISDATE和GLZD_ISTIME为1，如自定义主键由多个字段组成LGID|FJH，那么对应的GLZD_ISDATE和GLZD_ISTIME为0|0

*特别注意：此修改必须熟悉图库数据建模，如果不了解数据建模可参考数据建模手册
此修改过程如果有不明白的地方可以联系开发人员。*

#### 3.7.3 生成User节点CSV文件

注意：如果了解现场Hadoop集群的话，此过程必须由现场的Hadoop集群的管理员协助完成，其中的包由开发人员提供。

步骤：

1、打包相关的kshfx-0.1.0.jar到Hadoop集群的主节点的`/home/hadoop/Kshfx/jar/`目录下。

2、拷贝运行的Jar包到Hadoop集群的主节点的`/home/hadoop/Kshfx/libs/`目录下。

3、拷贝相关的shell执行文件到`/home/hadoop/Kshfx/bin/`目录下。

4、授权Shell执行脚步的执行权限
```sh
chmode 755 /home/hadoop/Kshfx/bin/*.sh
```

5、执行命令进行CSV文件生成

执行成功在配置的hdfs路径上找到相关的生成的CSV数据文件，拷贝到Neo4j服务器。

具体详情可以查看【现场实施手册】

#### 3.7.4 生成其他轨迹类节点和关系CSV文件

*此部分内容完全和上一节一致，需要修改的是执行命令参数修改即可。*

3.8 全量导入Neo4j图库

我们通过上一章节介绍了生成CSV数据文件，本机拷贝到Batch Import的服务器上，那么直接通过Batch Import的import命令进行导入生成新的图库。Batch Import如何使用请阅读【[Neo4j-Batch-Import使用手册V0.1.0]("" "Neo4j-Batch-Import使用手册V0.1.0")】。

比如已经生成了相关user.csv,hotel.csv,hotel-rels.csv的CSV数据文件并且拷贝到Batch Import服务器，执行下面命令进行生成：
```sh
import ..\data\databases\kshfx.db csv\kshfx\user.csv,csv\kshfx\hotel.csv csv\kshfx\hotel-rels.csv.csv
```

生成kshfx.db新的图数据库后，Neo4j切换图数据，即可使用。

## 第四章 增量方案

### 4.1.增量实现原理

为了保证数据的一致性和数据节点和关系的唯一性原则，那么只能使用Cypher的Merge的方法进行增量的入库方式。增量方案使用Flume动态实时读取Oralce标准库的实时增量并且使用Pool方式推送到Spark Streaming，然后Spark 流处理实时在线的方式读取增量时间组装Cypher语句进行增量Neo4j的数据写入。

### 4.2.优缺点

Neo4j为了保证节点和关系的实时增量和唯一性数据问题，只能考虑Merge的方式，这样的合并处理会损失大量的性能。
此方案的优点：
1、可以完全保证实时性，5s-10s的范围增量时间差
2、可以保证数据的唯一性，使用Merge进行合并
3、可以动态更新想要更新的属性

缺点：
1、通过Cypher本身性能就差，不到2000条/s
2、Merger合并写事务操作，更是消耗更多的性能，速度会下降几个数量级
3、Spark Stream流处理的检查点需要再进一步完善
4、需要添加Flume的SQL插件，兼容Hadoop平台需要需要结合生产环境测试验证

### 4.3.增量方案流程图

Oracle -->Flume-->Spark流-->Neo4j图库

![](https://v4liulv.github.io/assets/image/1522384223866_43.png)

### 4.4.增量实现

备：本方案基于CDH5.7.1进行测试可行性，验证增量正常

增量实现注意以下几点：
1、FlumeSQL插件兼容性
本身Flume暂时不支持Oracle的数据增量的读取，需要使用FlumeSQL插件，可能会有兼容Flume版本问题，建议使用Flume1.6.0-cdh5.7.1，后续其他版本待测试验证
2、Flume ng 的配置SQL配置可参考【[Flume SQL NG配置手册]( "Flume SQL NG配置手册")】
3、Flume Pool方式数据到Spark Streaming注意其中的HDFS检查点配置
4、增量实现代码在[Kshfx-Spark模版]( "Kshfx-Spark模版")，这里不详细介绍，可以查看API
Neoj4 Cypher语句组装需要注意结合的业务和建模的实现主要考虑唯一性

4.5.实施部署

相关详情可以查看【[现场实施手册]( "现场实施手册")】
